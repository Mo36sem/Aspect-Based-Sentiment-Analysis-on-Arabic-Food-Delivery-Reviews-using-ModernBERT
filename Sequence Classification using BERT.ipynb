{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11604567,"sourceType":"datasetVersion","datasetId":7278498},{"sourceId":11604852,"sourceType":"datasetVersion","datasetId":7278707}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:53:55.181516Z","iopub.execute_input":"2025-04-28T21:53:55.181795Z","iopub.status.idle":"2025-04-28T21:53:55.500123Z","shell.execute_reply.started":"2025-04-28T21:53:55.181773Z","shell.execute_reply":"2025-04-28T21:53:55.499415Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/data-csv/All_data.xlsx\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:53:59.272887Z","iopub.execute_input":"2025-04-28T21:53:59.273656Z","iopub.status.idle":"2025-04-28T21:53:59.277403Z","shell.execute_reply.started":"2025-04-28T21:53:59.273631Z","shell.execute_reply":"2025-04-28T21:53:59.276696Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\ndf = pd.read_excel(\"/kaggle/input/data-csv/All_data.xlsx\")\n\ndef create_tag(row):\n    if row['aspect'] == 'O':\n        return 'O'\n    else:\n        return f\"{row['aspect']}-{row['categort']}\"\n\ndf['ner_tag'] = df.apply(create_tag, axis=1)\n\nsentences = []\nlabels = []\nfor _, group in df.groupby(\"Sentence #\"):\n    sentences.append(group[\"word\"].tolist())\n    labels.append(group[\"ner_tag\"].tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:54:01.307559Z","iopub.execute_input":"2025-04-28T21:54:01.307797Z","iopub.status.idle":"2025-04-28T21:54:07.654154Z","shell.execute_reply.started":"2025-04-28T21:54:01.307780Z","shell.execute_reply":"2025-04-28T21:54:07.653625Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n  warn(msg)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\nunique_labels = list(set(tag for doc in labels for tag in doc))\nlabel2id = {label: i for i, label in enumerate(sorted(unique_labels))}\nid2label = {i: label for label, i in label2id.items()}\n\ndata = {\"tokens\": sentences, \"ner_tags\": labels}\ntrain_texts, test_texts = train_test_split(pd.DataFrame(data), test_size=0.2, random_state=42)\n\ntrain_dataset = Dataset.from_pandas(train_texts.reset_index(drop=True))\ntest_dataset = Dataset.from_pandas(test_texts.reset_index(drop=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:54:10.792805Z","iopub.execute_input":"2025-04-28T21:54:10.793151Z","iopub.status.idle":"2025-04-28T21:54:12.854267Z","shell.execute_reply.started":"2025-04-28T21:54:10.793130Z","shell.execute_reply":"2025-04-28T21:54:12.853749Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"aubmindlab/bert-base-arabertv2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], is_split_into_words=True, truncation=True, padding=\"max_length\", max_length=128)\n    labels = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        label_ids = []\n        previous_word_idx = None\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label2id[label[word_idx]])\n            else:\n                label_ids.append(label2id[label[word_idx]] if label[word_idx].startswith(\"I\") else -100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\ntokenized_train = train_dataset.map(tokenize_and_align_labels, batched=True)\ntokenized_test = test_dataset.map(tokenize_and_align_labels, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:54:15.763227Z","iopub.execute_input":"2025-04-28T21:54:15.763664Z","iopub.status.idle":"2025-04-28T21:54:24.941235Z","shell.execute_reply.started":"2025-04-28T21:54:15.763643Z","shell.execute_reply":"2025-04-28T21:54:24.940579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"445bc02b23194799abe6c044438ff182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed16f0bab333424c8085c0b5d72e0dff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/720k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d66a5f812a514fc09c3d20c154f52785"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0878379f4e842a7aa87fe69a5daa0f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d2d91479a044ea89b7321f7319e610c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3876 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d59ba27474448afaaa658621202d46f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/970 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8466f454f04c427fbda589db2e16937a"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_name,\n    num_labels=len(label2id),\n    id2label=id2label,\n    label2id=label2id\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:54:28.832531Z","iopub.execute_input":"2025-04-28T21:54:28.833194Z","iopub.status.idle":"2025-04-28T21:54:47.245028Z","shell.execute_reply.started":"2025-04-28T21:54:28.833173Z","shell.execute_reply":"2025-04-28T21:54:47.244310Z"}},"outputs":[{"name":"stderr","text":"2025-04-28 21:54:34.007622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745877274.187137      55 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745877274.238001      55 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86f8606337c44fbc950bd06c87b4c260"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install -U transformers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir=\"./logs\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:54:50.938022Z","iopub.execute_input":"2025-04-28T21:54:50.938929Z","iopub.status.idle":"2025-04-28T21:54:52.110554Z","shell.execute_reply.started":"2025-04-28T21:54:50.938903Z","shell.execute_reply":"2025-04-28T21:54:52.110003Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install seqeval --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:55:01.660618Z","iopub.execute_input":"2025-04-28T21:55:01.661301Z","iopub.status.idle":"2025-04-28T21:55:07.614200Z","shell.execute_reply.started":"2025-04-28T21:55:01.661277Z","shell.execute_reply":"2025-04-28T21:55:07.613479Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\nfrom seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\nimport numpy as np\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n    \n    true_predictions = [\n        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n        for pred, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n        for pred, label in zip(predictions, labels)\n    ]\n\n    return {\n        \"accuracy\": accuracy_score(true_labels, true_predictions),\n        \"precision\": precision_score(true_labels, true_predictions),\n        \"recall\": recall_score(true_labels, true_predictions),\n        \"f1\": f1_score(true_labels, true_predictions)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:55:13.694959Z","iopub.execute_input":"2025-04-28T21:55:13.695264Z","iopub.status.idle":"2025-04-28T21:55:13.708726Z","shell.execute_reply.started":"2025-04-28T21:55:13.695241Z","shell.execute_reply":"2025-04-28T21:55:13.708135Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_test,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:55:20.458840Z","iopub.execute_input":"2025-04-28T21:55:20.459121Z","iopub.status.idle":"2025-04-28T21:55:21.521006Z","shell.execute_reply.started":"2025-04-28T21:55:20.459100Z","shell.execute_reply":"2025-04-28T21:55:21.520243Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/582609331.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:55:27.043326Z","iopub.execute_input":"2025-04-28T21:55:27.044262Z","iopub.status.idle":"2025-04-28T21:59:02.154617Z","shell.execute_reply.started":"2025-04-28T21:55:27.044235Z","shell.execute_reply":"2025-04-28T21:59:02.154031Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1455' max='1455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1455/1455 03:33, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.395857</td>\n      <td>0.886167</td>\n      <td>0.617567</td>\n      <td>0.604789</td>\n      <td>0.611111</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.577500</td>\n      <td>0.370577</td>\n      <td>0.891075</td>\n      <td>0.632863</td>\n      <td>0.636417</td>\n      <td>0.634635</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.354700</td>\n      <td>0.370110</td>\n      <td>0.890183</td>\n      <td>0.627104</td>\n      <td>0.649719</td>\n      <td>0.638211</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1455, training_loss=0.41505222386101265, metrics={'train_runtime': 214.6042, 'train_samples_per_second': 54.183, 'train_steps_per_second': 6.78, 'total_flos': 759644611061760.0, 'train_loss': 0.41505222386101265, 'epoch': 3.0})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"results = trainer.evaluate()\nprint(results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:59:25.154050Z","iopub.execute_input":"2025-04-28T21:59:25.154333Z","iopub.status.idle":"2025-04-28T21:59:29.388254Z","shell.execute_reply.started":"2025-04-28T21:59:25.154313Z","shell.execute_reply":"2025-04-28T21:59:29.387635Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.3701102137565613, 'eval_accuracy': 0.8901829540383758, 'eval_precision': 0.6271041369472182, 'eval_recall': 0.6497191841560744, 'eval_f1': 0.638211382113821, 'eval_runtime': 4.2238, 'eval_samples_per_second': 229.651, 'eval_steps_per_second': 28.884, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"predictions, labels, _ = trainer.predict(tokenized_test)\n\npredictions = np.argmax(predictions, axis=2)\n\n\ntrue_predictions = [\n    [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n    for prediction, label in zip(predictions, labels)\n]\n\ntrue_labels = [\n    [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n    for prediction, label in zip(predictions, labels)\n]\n\nprint(\"Accuracy:\", accuracy_score(true_labels, true_predictions))\nprint(\"Precision:\", precision_score(true_labels, true_predictions))\nprint(\"Recall:\", recall_score(true_labels, true_predictions))\nprint(\"F1 Score:\", f1_score(true_labels, true_predictions))\n\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(true_labels, true_predictions))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:06:31.524085Z","iopub.execute_input":"2025-04-28T22:06:31.524398Z","iopub.status.idle":"2025-04-28T22:06:36.146546Z","shell.execute_reply.started":"2025-04-28T22:06:31.524345Z","shell.execute_reply":"2025-04-28T22:06:36.145950Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Accuracy: 0.8901829540383758\nPrecision: 0.6271041369472182\nRecall: 0.6497191841560744\nF1 Score: 0.638211382113821\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n    Location       0.53      0.50      0.52       215\n       Price       0.65      0.71      0.68       765\n     Service       0.58      0.61      0.60      1597\n        Time       0.72      0.72      0.72       806\n\n   micro avg       0.63      0.65      0.64      3383\n   macro avg       0.62      0.63      0.63      3383\nweighted avg       0.63      0.65      0.64      3383\n\n","output_type":"stream"}],"execution_count":16}]}